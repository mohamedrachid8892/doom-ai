{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3e8a33-6fc3-4881-855f-185032e7a9c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Get VizDoom Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d72d31-3b43-49c5-9fd4-26f9b172d647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vizdoom in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.1.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from vizdoom) (1.24.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2858ba5-8a11-4e66-b166-81b3dd471054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ViZDoom' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3994bc91-d4c3-403f-b86a-0d9fa58c59cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import vizdoom for game environment\n",
    "from vizdoom import *\n",
    "# Import random to take random actions\n",
    "import random\n",
    "# Import time to slow down game, sleep between frames\n",
    "import time\n",
    "# Import numpy for identity matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2901405e-8dd6-4a73-bb6a-779db1b45715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Game\n",
    "game = DoomGame()\n",
    "game.load_config('github/ViZDoom/scenarios/defend_the_center.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f394bfb-ce13-437b-98c1-d50923601ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the actions we can take in the environment - Move left, move right, attack\n",
    "actions = np.identity(3, dtype=np.uint8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdae2b0-ba77-49b4-b1b0-53e98770620c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960fffb8-5d08-4b44-9c5f-5c76cf239a07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: -1.0\n",
      "Result: -1.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 1.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: -1.0\n",
      "Result: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 1.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: -1.0\n",
      "Result: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: 0.0\n",
      "Reward: -1.0\n",
      "Result: -1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Print total reward for full game\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult:\u001b[39m\u001b[38;5;124m'\u001b[39m, game\u001b[38;5;241m.\u001b[39mget_total_reward())\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through episodes\n",
    "episodes = 10 # Number of games to play\n",
    "for episode in range(episodes):\n",
    "    # Create new episode or game\n",
    "    game.new_episode()\n",
    "    # Check that the game isn't done\n",
    "    while not game.is_episode_finished():\n",
    "        # Get the game state\n",
    "        state = game.get_state()\n",
    "        # Get the game image\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables (in this case, ammo)\n",
    "        info = state.game_variables\n",
    "        # Take an action. Pass in frame skip to give AI time to process each action reward\n",
    "        reward = game.make_action(random.choice(actions), 4)\n",
    "        # Print the reward for each action\n",
    "        print('Reward:', reward)\n",
    "        time.sleep(0.02)\n",
    "    # Print total reward for full game\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79c2ce0-96a8-44c0-9d72-562ee22f5da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5026b1c4-52c6-4b0c-ad28-9b4f04b87be9",
   "metadata": {},
   "source": [
    "# 2. Converting the Environment to a Gym Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3aaaecf-12e5-4ac9-9eab-272000d7723a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gym) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gym) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bac96f0-76a0-4826-bddd-1fc6332ca1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import environment base class from OpenAI Gym\n",
    "from gym import Env\n",
    "# Import gym spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "# Import opencv, Used to greyscale observations to make processing environment faster\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c715b10-23ac-4e4f-8a38-d76bbea4e096",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create VIZDoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env):\n",
    "    \n",
    "    # Function that is called when we start the environment\n",
    "    def __init__(self, render=False):\n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        \n",
    "        # Setup the game\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/ViZDoom/scenarios/defend_the_center.cfg') # Pass in whatever environment you need from the scenarios folder.\n",
    "        \n",
    "        # Define whether or not to render the game window.\n",
    "        # Rendering the window takes away from computing power, so disabling is ideal for testing\n",
    "        if render == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        self.game.init()\n",
    "        \n",
    "        # Create the action and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "    \n",
    "    # How we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step within game\n",
    "        actions = np.identity(3, dtype=np.uint8)\n",
    "        reward = self.game.make_action(actions[action], 4)\n",
    "        \n",
    "        # Get all other stuff we need to return\n",
    "        if self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.greyscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0\n",
    "            \n",
    "        info = {\"info\": info}\n",
    "            \n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info\n",
    "    \n",
    "    # Define how to render the game or environment. ViZDOom already defines this for us, so just pass.\n",
    "    def render():\n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new gmae\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.greyscale(state)\n",
    "    \n",
    "    # Custom function. Greyscale the game frame and resize it\n",
    "    def greyscale(self, observation):\n",
    "        # Reshape the observation array for cvtColor and change color channels\n",
    "        grey = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        # Resize the image and scale down so there are less pixels to process\n",
    "        resize = cv2.resize(grey, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100, 160, 1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f59f82-04e8-4a83-b08a-68f7fb33336b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b4cdf-d439-4214-b9c2-492bc66f4e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7342b8-d2d9-4ad0-8dc1-af9492fe8c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7be77c-5454-4f1f-823e-c9a3e256ebdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Environment checker\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e0ece-bc75-4476-b422-7f649eb21580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb60e5-300a-4db1-ba42-b7e632948217",
   "metadata": {},
   "source": [
    "# 3. View State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95645a20-1b3d-423f-afae-9fa0ab926ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e51f0a-2e6d-4d24-843f-85054082d69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c257ff4d-cdff-4eb4-b97d-4e9a16eacd94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[43mstate\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(cv2.cvtColor(state, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c7913-a145-42d0-9633-7768a49846d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Log the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2f72c4c-f4da-4a97-88ee-80ae5635cbaa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: torchvision in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.15.1+cu117)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.1+cu117)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->torchvision) (1.26.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6896a25-94fe-4d58-b4ab-6bd49134a9b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (2.0.1)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0+cu117)\n",
      "Requirement already satisfied: importlib-metadata~=4.13 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (4.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (1.24.3)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (3.7.1)\n",
      "Requirement already satisfied: opencv-python; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (4.7.0.72)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (5.9.5)\n",
      "Requirement already satisfied: tqdm; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: ale-py==0.7.4; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: pillow; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (9.5.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (2.12.2)\n",
      "Requirement already satisfied: rich; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (13.3.4)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.6.0; extra == \"extra\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (5.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.39.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm; extra == \"extra\"->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2.17.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (41.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.54.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (4.22.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.40.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2.29.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rich; extra == \"extra\"->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rich; extra == \"extra\"->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (8.1.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license; extra == \"accept-rom-license\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch>=1.11->stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3[extra]) (1.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich; extra == \"extra\"->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1; extra == \"extra\"->stable-baselines3[extra]) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 23.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7591c06-e1c1-4fa6-8664-a5c8bfa6bcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file navigation\n",
    "import os\n",
    "# Import callback class from stable baselines 3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0242c4f-0ef5-438b-aa80-39ced1dbe050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3ff888-d59f-4895-94b5-f56c11c1e759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_defend_center'\n",
    "LOG_DIR = './logs/log_defend_center'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be35ef98-40ae-44c9-a5aa-791bf49baa57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3e0ee-3b14-47fb-b380-c215d5f51484",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6137cab1-18c1-44cb-a43f-2dc3d4b27ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the PPO algorithm for training\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "931f1e85-6d8d-4549-aa47-ed08293f6161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "341faec1-c18f-4df6-a627-640438a978a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# CnnPolicy because we are passing in an image\n",
    "# Cnn = Convolution neural network\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5c0d31f-71b7-44cc-bae6-bf5f0dc9a9f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_defend_center\\PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 81.7     |\n",
      "|    ep_rew_mean     | 0.28     |\n",
      "| time/              |          |\n",
      "|    fps             | 49       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86          |\n",
      "|    ep_rew_mean          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010422496 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0336     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 92.3        |\n",
      "|    ep_rew_mean          | 1.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013574613 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0127      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 94.9         |\n",
      "|    ep_rew_mean          | 1.37         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075518396 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0236       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.5         |\n",
      "|    ep_rew_mean          | 1.49         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096531445 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.988       |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0141       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    value_loss           | 0.177        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 1.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008167967 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | 2.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010535914 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00193    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.033      |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 105        |\n",
      "|    ep_rew_mean          | 2.32       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01292432 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.96      |\n",
      "|    explained_variance   | 0.614      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0354    |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0308    |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 2.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013677181 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | 2.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019496717 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0477     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | 3.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018174224 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0374     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 125         |\n",
      "|    ep_rew_mean          | 3.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018076293 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0404     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 132        |\n",
      "|    ep_rew_mean          | 4.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 541        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02045076 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.843     |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0461    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    value_loss           | 0.173      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | 4.96        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021933358 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0453     |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 5.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017789572 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.75       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 5.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 713         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027295832 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 156         |\n",
      "|    ep_rew_mean          | 6.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022578083 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | 6.81        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022241423 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00985    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 7.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022493798 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | 7.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 962         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020164382 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 185         |\n",
      "|    ep_rew_mean          | 8.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024312802 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    247\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:163\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:95\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m---> 95\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:54\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 54\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32mc:\\users\\moham\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:95\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m, in \u001b[0;36mVizDoomGym.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Specify action and take step within game\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39midentity(\u001b[38;5;241m3\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m---> 30\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Get all other stuff we need to return\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mget_state():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8574072-c7ea-4146-bad4-d5638704de87",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "To view the logs run `tensorboard --logdir=.` in the PPO dir of the model run.  (CHECK 1 42 00 IN THE VIDEO FOR EXPLANATION)\n",
    "Explaining the data:  \n",
    "> 1. `ep_len_mean`: Mean episode length (averaged over stats_window_size episodes, 100 by default)\n",
    "> 2. `ep_rew_mean`: Mean episodic training reward (averaged over stats_window_size episodes, 100 by default).\n",
    "> 3.\n",
    "> 4.\n",
    "> 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeb17f-924c-40ad-a36a-f2a6f5a26be5",
   "metadata": {},
   "source": [
    "# 6. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ac0ba5b-b920-43cc-ae54-85de3ca226db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import eval policy to test agent\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca591ce-a954-418e-bbcd-ca651961e90f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reload model from disc\n",
    "model = PPO.load('./train/train_defend_center/best_model_70000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c807842e-2155-444b-830f-f834723646e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create rendered environment\n",
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "261d95c2-acf7-4e33-87d8-855f66e382a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate mean reward for 100 games\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a004cba-0244-47fd-9d3b-970083faf02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.99"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af99ad8b-e35f-49db-acb9-ef960d8d8d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward for episode 0 is 16.0\n",
      "Total reward for episode 1 is 18.0\n",
      "Total reward for episode 2 is 17.0\n",
      "Total reward for episode 3 is 16.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n\u001b[0;32m      7\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.125\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal reward for episode \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(episode, total_reward))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(5):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.125)\n",
    "        total_reward += reward\n",
    "    print('Total reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89174c2-3a1c-4d60-93f7-d2b212d2c152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5b7b1-5cc0-454b-b8d4-c95066c3cb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
